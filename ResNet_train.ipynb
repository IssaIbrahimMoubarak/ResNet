{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eispJBJUKmjG"
   },
   "source": [
    "## Hello everybody üòÉ üòÉ welcome back\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ysLDm91jNg-c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Image Size\n",
    "IMG_ROWS, IMG_COLS = 64, 64 # input image dimensions\n",
    "NB_CLASSES =  4 # number of outputs = number of digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pIdma5T4WSnW"
   },
   "source": [
    "## (01)   ACQUISITION DES DONNEES - IMAGES DES FEUILLES DES PLANTES. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SvgdwdQCZFLa"
   },
   "outputs": [],
   "source": [
    "########################################### function for plotting images\n",
    "\n",
    "def plot_images(images, total_images=100, rows=20, cols=5, fsize=(20,100), titre='Image'):\n",
    "    \n",
    "    fig = plt.figure(figsize=fsize) # create a new figure window\n",
    "    \n",
    "    for i in range(total_images): # display images\n",
    "        # subplot : 33 rows and 5 columns\n",
    "        img_grid = fig.add_subplot(rows, cols, i+1)\n",
    "        # plot features as image\n",
    "        img_grid.imshow(images[i])\n",
    "        \n",
    "        plt.title(titre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAJ4GmbT72p0"
   },
   "outputs": [],
   "source": [
    "############################################ function for resizng images\n",
    "       \n",
    "def preprocess_image(image, image_height=IMG_ROWS, image_width=IMG_COLS):\n",
    "\n",
    "    return cv2.resize(image, (image_height, image_width))\n",
    "\n",
    "############################################ function for reading images \n",
    "       \n",
    "def read_images (path , sz= None ):\n",
    "    \n",
    "    print('\\nCHARGEMENT DES IMAGES DE LA BASE .......................!\\n') \n",
    "\n",
    "    X,y = [], []\n",
    "    \n",
    "    for dirname , dirnames , filenames in os.walk(path):\n",
    "        \n",
    "        c = 0\n",
    "        \n",
    "        for subdirname in dirnames :\n",
    "            \n",
    "            subject_path = os. path . join ( dirname , subdirname )\n",
    "            \n",
    "            for filename in os. listdir ( subject_path ):\n",
    "                \n",
    "                im = Image.open(os.path.join(subject_path, filename))\n",
    "                #im = im.convert (\"L\")\n",
    "\n",
    "                if (sz is not None ):\n",
    "                    im = im.resize (sz , Image.ANTIALIAS ) \n",
    "                    \n",
    "                im = np.array(im)\n",
    "                im = preprocess_image(im, IMG_ROWS, IMG_COLS)\n",
    "                X.append(im)\n",
    "                y.append (c)  \n",
    "                \n",
    "            c = c+1\n",
    "            \n",
    "    return [X,y]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################ Read And Resize test images\n",
    "\n",
    "print('\\n\\nLECTURE DES IMAGES DE LA BASE D\\'APPRENTISSAGE........!') \n",
    "\n",
    "[X_train, y_train] = read_images(\"C:/Users/Dell 7280/Documents/Etude/ESCEP/S3/Deep learning/Corrections/TP4-Tomato/Data/TrainData\") # Potato\n",
    "\n",
    "print('\\nAFFICHAGE DE QUELQUES IMAGES DE LA BASE.................!')\n",
    "plot_images(X_train, 2, 1, 2,(10, 50), titre='Base D\\'Apprentissage')\n",
    "plt.show()\n",
    "print('\\nFIN D\\'AFFICHAGE DES IMAGES DE LA BASE...................!\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################# Train Data\n",
    "\n",
    "# Train Data\n",
    "images_train = np.asarray(X_train)\n",
    "\n",
    "# Train targets\n",
    "train_features = images_train\n",
    "train_targets = np.asarray(y_train)\n",
    "\n",
    "NB_CLASSES = np.max(train_targets) + 1\n",
    "\n",
    "# V√©rifiez les valeurs uniques dans train_targets\n",
    "unique_classes = np.unique(train_targets)\n",
    "print(f\"Unique classes in train_targets: {unique_classes}\")\n",
    "\n",
    "# V√©rifiez que les valeurs d'index ne d√©passent pas NB_CLASSES\n",
    "if np.any(train_targets >= NB_CLASSES):\n",
    "    raise ValueError(f\"Certaines √©tiquettes dans train_targets sont sup√©rieures ou √©gales √† NB_CLASSES={NB_CLASSES}\")\n",
    "\n",
    "# Convertir les vecteurs de classe en matrices de classe binaires\n",
    "train_targets = to_categorical(train_targets, NB_CLASSES)\n",
    "\n",
    "print('\\nNORMALISATION DES BASES DE TEST ET D\\'APPRENTISSAGE.\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################## Normalisation\n",
    "\n",
    "train_features = train_features.astype('float32')\n",
    "\n",
    "mean_vals = np.mean(train_features, axis=0)\n",
    "std_val = np.std(train_features)\n",
    "train_features = (train_features - mean_vals)/std_val\n",
    "\n",
    "train_features = train_features.reshape(train_features.shape[0], IMG_ROWS, IMG_COLS, 3)\n",
    "print(\"train_features.shape     >==============<> : {}\".format(train_features.shape))\n",
    "print(\"train_targets.shape      >==============<> : {}\".format(train_targets.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################\n",
    "#(02)        CLASSIFICATION : CREATION DU MODELE DE PREDICTION         #\n",
    "########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import AveragePooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Activation, Dropout\n",
    "from keras.layers import add, Input\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "import time\n",
    "from keras.initializers import HeNormal\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d√©finissant un bloc ResNet\n",
    "def resnet_block(input_tensor, filters, kernel_size=3, stride=1, dropout_rate=0.3):\n",
    "    # Premi√®re convolution\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, strides=stride, padding='same', kernel_initializer=HeNormal())(input_tensor)\n",
    "    # Normalisation par lot\n",
    "    x = BatchNormalization()(x)\n",
    "    # Activation ReLU\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout_rate)(x) \n",
    "    \n",
    "    # Activation ReLU\n",
    "    x = Conv2D(filters, kernel_size=kernel_size, padding='same', kernel_initializer=HeNormal())(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    # Si le stride n'est pas √©gal √† 1, ajuster l'input_tensor pour correspondre √† la dimension de sortie\n",
    "    if stride != 1:\n",
    "        input_tensor = Conv2D(filters, kernel_size=1, strides=stride, padding='same', kernel_initializer=HeNormal())(input_tensor)\n",
    "        input_tensor = BatchNormalization()(input_tensor)\n",
    "    x = add([x, input_tensor])\n",
    "    x = Activation('relu')(x)\n",
    "    return x\n",
    "\n",
    "def build_resnet(input_shape, classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, kernel_size=7, strides=2, padding='same', kernel_initializer=HeNormal())(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    \n",
    "    # Add ResNet blocks\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 64)\n",
    "    for _ in range(4):\n",
    "        x = resnet_block(x, 128, stride=2 if _ == 0 else 1)\n",
    "    for _ in range(6):\n",
    "        x = resnet_block(x, 256, stride=2 if _ == 0 else 1)\n",
    "    for _ in range(3):\n",
    "        x = resnet_block(x, 512, stride=2 if _ == 0 else 1)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)  # Add Dropout before the output layer\n",
    "    outputs = Dense(classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©finition de l'optimiseur et des param√®tres\n",
    "OPTIMIZER = Adam()\n",
    "IMG_ROWS, IMG_COLS = 64, 64  # Mettez les dimensions correctes de vos images ici\n",
    "INPUT_SHAPE = (IMG_ROWS, IMG_COLS, 3)\n",
    "NB_CLASSES = 10  # Changez ceci selon votre nombre de classes\n",
    "NB_EPOCH = 100\n",
    "BATCH_SIZE = 64\n",
    "VERBOSE = 1\n",
    "\n",
    "# Redimensionnement des donn√©es d'entr√©e\n",
    "def resize_images(images, target_size):\n",
    "    resized_images = np.zeros((images.shape[0], *target_size, 3))\n",
    "    for i, img in enumerate(images):\n",
    "        resized_images[i] = np.resize(img, (*target_size, 3))\n",
    "    return resized_images\n",
    "\n",
    "# Charger et redimensionner les images d'entra√Ænement\n",
    "train_features = resize_images(np.asarray(X_train), (IMG_ROWS, IMG_COLS))\n",
    "\n",
    "# Convertir les √©tiquettes en matrices de classe binaires\n",
    "train_targets = to_categorical(np.asarray(y_train), NB_CLASSES)\n",
    "\n",
    "print('\\nNORMALISATION DES BASES DE TEST ET D\\'APPRENTISSAGE.\\n')\n",
    "\n",
    "# Normalisation des donn√©es\n",
    "train_features = train_features.astype('float32')\n",
    "mean_vals = np.mean(train_features, axis=0)\n",
    "std_val = np.std(train_features)\n",
    "train_features = (train_features - mean_vals) / std_val\n",
    "\n",
    "# V√©rifiez les dimensions des donn√©es\n",
    "print(\"train_features.shape     >==============<> : {}\".format(train_features.shape))\n",
    "print(\"train_targets.shape      >==============<> : {}\".format(train_targets.shape))\n",
    "\n",
    "def build_resnet(input_shape, classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = Conv2D(64, kernel_size=7, strides=2, padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = AveragePooling2D(pool_size=2, strides=2, padding='same')(x)\n",
    "    # Ajoutez les couches suppl√©mentaires pour votre mod√®le ResNet ici\n",
    "\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    outputs = Dense(classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Construction et compilation du mod√®le ResNet\n",
    "model = build_resnet(input_shape=INPUT_SHAPE, classes=NB_CLASSES)\n",
    "model.compile(optimizer=OPTIMIZER, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Affichage du r√©sum√© du mod√®le\n",
    "model.summary()\n",
    "\n",
    "# Enregistrement du temps de d√©but d'entra√Ænement\n",
    "t_start = time.time()\n",
    "\n",
    "# Entra√Ænement du mod√®le\n",
    "history = model.fit(train_features, train_targets, batch_size=BATCH_SIZE, epochs=NB_EPOCH, verbose=VERBOSE)\n",
    "\n",
    "# Calcul du temps total d'entra√Ænement\n",
    "time_full_train = time.time() - t_start\n",
    "\n",
    "# Affichage du temps d'entra√Ænement\n",
    "print(\"\\nTEMPS D'APPRENTISSAGE DU CLASSIFIEUR >====<> : %0.2fs \" % (time_full_train))\n",
    "\n",
    "# Sauvegarde du mod√®le entra√Æn√©\n",
    "model.save(\"ResNet_model_groupe_2.h5\")\n",
    "print('\\nENREGISTRER LE MODELE .\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measure of AlexNet for one dataset patato\n",
    "1.  83.02%\n",
    "2.  89.26%\n",
    "3.  88.95%\n",
    "4.  84.88%\n",
    "5.  84.88%\n",
    "6.  84.42%\n",
    "7.  83.26%\n",
    "8.  84.42%\n",
    "9.  89.79%\n",
    "10. 83.49%\n",
    "Result of AlexNet for ten test = 84.90 %"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
